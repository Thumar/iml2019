{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# Tutorial: Advanced Generative Adversarial Network Techniques"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(\u0027TensorFLow version\u0027, \u00271.13.1\u0027)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import numpy as np\nimport tensorflow as tf\nfrom plotting import plot_images\nimport tutorial\nlayers \u003d tf.layers\nprint(\"TensorFLow version\", tf.__version__)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "Let\u0027s start to build a data pipeline.\nFirst we need to define our Data generator.\nThe generator should output real samples (input for the discriminator) and noise (input for the generator)\nThe variable LATENT_DIM defines the dimensionality of the latent space of the generator.\n(The noise distribution we sample from)."
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "def generator(LATENT_DIM):\n    while True:\n        (x_train, y_train), (x_test, y_test) \u003d tf.keras.datasets.mnist.load_data()\n        images \u003d (np.expand_dims(x_train, axis\u003d-1)) / 255.\n        images \u003d images.astype(np.float32)\n        noise \u003d np.random.randn(60000, LATENT_DIM).reshape(60000, LATENT_DIM)\n        idx \u003d np.random.permutation(60000)\n        noise \u003d noise[idx]\n        images \u003d images[idx]\n        for i in range(60000):\n            yield (noise[i], images[i])"
    },
    {
      "cell_type": "markdown",
      "source": "Let us now check if our generator is working",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "data": {
            "text/plain": "(1, 2)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 6
        }
      ],
      "source": "import itertools\ntest_image \u003d np.array(list(itertools.islice(generator(64), 1)))\ntest_image.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To train our estimator we can make create a TensorflowDataset out of our data generator.\nThe function outputs a batches of our dataset.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": "def batch_dataset(BATCH_SIZE, LATENT_DIM, generator_fn):\n    Dataset \u003d tf.data.Dataset.from_generator(\n        lambda: generator_fn(LATENT_DIM), output_types\u003d(tf.float32, tf.float32),\n        output_shapes\u003d(tf.TensorShape((LATENT_DIM,)), tf.TensorShape((28, 28, 1))))\n    return Dataset.batch(BATCH_SIZE)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "For training a GAN we nee to further define our generator and discriminator network.\nWe start by defining our generator network, which should map from our noise space into the space of out images (LATENT_DIM --\u003e IMAGE_DIM)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": "def generator_fn(x, latent_dim\u003dLATENT_DIM):\n    x \u003d layers.Dense(7 * 7 * 128, activation\u003d\u0027relu\u0027, input_shape\u003d(latent_dim,))(x)  #\n    x \u003d tf.reshape(x, shape\u003d[BATCH_SIZE, 7, 7, 128])\n    x \u003d layers.Conv2DTranspose(128, (5, 5), strides\u003d(2, 2), padding\u003d\u0027same\u0027, activation\u003d\u0027relu\u0027)(x)\n    x \u003d layers.Conv2DTranspose(64, (5, 5), strides\u003d(2, 2), padding\u003d\u0027same\u0027, activation\u003d\u0027relu\u0027)(x)\n    x \u003d layers.Conv2D(1, (5, 5), padding\u003d\u0027same\u0027, activation\u003d\u0027sigmoid\u0027)(x)\n    return x",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "After defining our generator network we need now to implement our discriminator.\nThe task of the discriminator is to measure the similarity between the fake images (output of the generator) and the real images.\nSo, the network maps from the image space into a 1D space where we can measure the \u0027distance\u0027 between the distributions of the real and generated images.  (IMAGE_DIM --\u003e 1)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": "def discriminator_fn(x, drop_rate\u003d0.25):\n    \"\"\" Discriminator network \"\"\"\n    x \u003d layers.Conv2D(32, (5, 5), padding\u003d\u0027same\u0027, strides\u003d(2, 2), activation\u003d\u0027relu\u0027, input_shape\u003d(28, 28, 1))(x)\n    x \u003d tf.nn.leaky_relu(x, 0.2)\n    x \u003d layers.Conv2D(64, (5, 5), padding\u003d\u0027same\u0027, strides\u003d(2, 2), activation\u003d\u0027relu\u0027)(x)\n    x \u003d tf.nn.leaky_relu(x, 0.2)\n    x \u003d layers.Conv2D(128, (5, 5), padding\u003d\u0027same\u0027, strides\u003d(2, 2), activation\u003d\u0027relu\u0027)(x)\n    x \u003d tf.nn.leaky_relu(x, 0.2)\n    x \u003d layers.Flatten()(x)\n    x \u003d layers.Dense(256)(x)\n    x \u003d tf.nn.leaky_relu(x, 0.2)\n    x \u003d layers.Dense(1)(x)\n    return x",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "As Wasserstein-1 is a meaningful distance measure for disjoint distributions let\u0027s use it as objective of our GAN training.\nWe can very easily make use of the losses predefined in tf.contrib.gan.\nThe are 2 possible constraints to construct the Wasserstein distance:\n- Use weight clipping\n- Penalize the gradient\n\n(Easy interpretation: We need a constraint to train the discriminator to convergence, otherwise the discriminator could focus on one feature which differs between real and fake samples and won\u0027t converge)\nWeight clamping will heavily reduce the capacity of the discriminator which is unfavourable.\nSo let use use the Gradient Penalty (https://arxiv.org/abs/1704.00028):\nBy penalizing the gradient to be smaller than 1, we enforce the lipschitz constraint needed to construct Wasserstein using the Kantorovich-Rubinstein duality(https://cedricvillani.org/wp-content/uploads/2012/08/preprint-1.pdf)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": "def discrimintator_loss(model, add_summaries\u003dTrue):\n\n    loss \u003d tf.contrib.gan.losses.wasserstein_discriminator_loss(model, add_summaries\u003dadd_summaries)\n    gp_loss \u003d GP * tf.contrib.gan.losses.wasserstein_gradient_penalty(model, epsilon\u003d1e-10, one_sided\u003dTrue, add_summaries\u003dadd_summaries)\n    loss +\u003d gp_loss\n\n    if add_summaries:\n        tf.summary.scalar(\u0027discriminator_loss\u0027, loss)\n\n    return loss",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "After defining our loss we can choose our training parameters",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": "BATCH_SIZE \u003d 32  # number of samples fed into the framework in each iteration\nLATENT_DIM \u003d 64  # dimension of the generators latent space\nGEN_LR \u003d 0.001   # learning rate of the generator\nDIS_LR \u003d 0.0001  # learning rate of the discriminator\nITER \u003d 1000      # framework iterations\nLOG_DIR \u003d \".\"    # directory of the estimator (to save the graph and checkpoints)\ndir \u003d tutorial.make_dir(LOG_DIR, \"WGAN_GP\")\nGP \u003d 10          # factor to scale the gradient penalty (higher means larger enforcing the Lipschitz constrain)\nN_CRIT \u003d 5       # number of critic iterations per generator iterations.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now we can very easily implement our framework as estimator using tfgan.\nThis will heavily simplify our training procedure.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {\u0027_save_checkpoints_secs\u0027: None, \u0027_num_ps_replicas\u0027: 0, \u0027_keep_checkpoint_max\u0027: 1, \u0027_task_type\u0027: \u0027worker\u0027, \u0027_global_id_in_cluster\u0027: 0, \u0027_is_chief\u0027: True, \u0027_cluster_spec\u0027: \u003ctensorflow.python.training.server_lib.ClusterSpec object at 0x7feb89959890\u003e, \u0027_model_dir\u0027: \u0027./WGAN_GP_train_2019-04-04_17:03:06\u0027, \u0027_protocol\u0027: None, \u0027_save_checkpoints_steps\u0027: 200, \u0027_keep_checkpoint_every_n_hours\u0027: 10000, \u0027_service\u0027: None, \u0027_session_config\u0027: allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, \u0027_tf_random_seed\u0027: None, \u0027_save_summary_steps\u0027: 10, \u0027_device_fn\u0027: None, \u0027_experimental_distribute\u0027: None, \u0027_num_worker_replicas\u0027: 1, \u0027_task_id\u0027: 0, \u0027_log_step_count_steps\u0027: 100, \u0027_evaluation_master\u0027: \u0027\u0027, \u0027_eval_distribute\u0027: None, \u0027_train_distribute\u0027: None, \u0027_master\u0027: \u0027\u0027}\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "tfgan \u003d tf.contrib.gan\ngan_estimator \u003d tfgan.estimator.GANEstimator(\n    dir,\n    generator_fn\u003dgenerator_fn,\n    discriminator_fn\u003ddiscriminator_fn,\n    generator_loss_fn\u003dtfgan.losses.wasserstein_generator_loss,\n    discriminator_loss_fn\u003ddiscrimintator_loss,\n    generator_optimizer\u003dtf.train.AdamOptimizer(GEN_LR, 0.5),\n    discriminator_optimizer\u003dtf.train.AdamOptimizer(DIS_LR, 0.5),\n    get_hooks_fn\u003dtfgan.get_sequential_train_hooks(tfgan.GANTrainSteps(1, N_CRIT)),\n    config\u003dtf.estimator.RunConfig(save_summary_steps\u003d10, keep_checkpoint_max\u003d1, save_checkpoints_steps\u003d200),\n    use_loss_summaries\u003dTrue)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Let us train our framework using our gan_estimator and our data_pipeline",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /home/jonas/.local/lib/python2.7/site-packages/tensorflow/contrib/gan/python/losses/python/losses_impl.py:101: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
            "WARNING:tensorflow:From /home/jonas/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./WGAN_GP_train_2019-04-04_17:03:06/model.ckpt.\n",
            "INFO:tensorflow:loss \u003d 0.041437, step \u003d 1\n",
            "INFO:tensorflow:global_step/sec: 0.434456\n",
            "INFO:tensorflow:loss \u003d -5.485588, step \u003d 101 (230.182 sec)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "gan_estimator.train(lambda: batch_dataset(BATCH_SIZE, LATENT_DIM, generator), steps\u003dITER)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}